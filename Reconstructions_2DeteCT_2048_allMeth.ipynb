{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd5eea9",
   "metadata": {},
   "source": [
    "### Reconstructions_2DeteCT_dataset_Script\n",
    "\n",
    "This script is used to produce the reconstructions for the sinogram data of the 2DeteCT dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9e690",
   "metadata": {},
   "source": [
    "#### Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d4396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains a function for reconstructing sinogram data for the 2DeteCT dataset.\n",
    "\n",
    "import astra\n",
    "import imageio\n",
    "import warnings\n",
    "from typing import Any\n",
    "\n",
    "import glob # Used for browsing through the directories.\n",
    "import os # Used for creating directories.\n",
    "import shutil # Later used for copying files.\n",
    "import time # Used for keeping processing time.\n",
    "from tqdm.notebook import tqdm_notebook # Used for tracking progress.\n",
    "import NesterovGradient # Used for reconstruction method 'AGD'.\n",
    "import ReadingSettings_2DeteCT # Used to read in the acquisition settings from a machine-readable .csv file\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d # Used for detector shift via linear grid interpolation.\n",
    "from scipy.sparse.linalg import lsqr # Used for reconstruction method 'LS'.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95615d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories.\n",
    "# We enter here some intrinsic details of the dataset needed for our reconstruction scripts.\n",
    "# Set the variable \"base_data_dir_str\" to the path where the dataset is stored on your own workstation.\n",
    "base_data_dir_str = '/export/scratch2/mbk/2DeteCT_tests/test1/'\n",
    "\n",
    "# Set the variable \"save_dir_str\" to the path where you would like to store the reconstructions you compute.\n",
    "save_dir_str = '/export/scratch2/mbk/2DeteCT_tests/test1_recons/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafbedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined settings.\n",
    "\n",
    "# Select the ID(s) of the slice(s) you want to reconstruct.\n",
    "import random\n",
    "slice_id = range(10,11) #random.sample(range(1, 6370+1), 50)\n",
    "# Adjust this to your liking.\n",
    "\n",
    "# Select which modes you want to reconstruct.\n",
    "modes = range(3,4) # (1,2,3) #These are all modes available.\n",
    "\n",
    "# Define whether you have a GPU for computations available.\n",
    "use_GPU = True\n",
    "gpuIndex = 0 # Set the index of the GPU card used.\n",
    "astra.set_gpu_index(gpuIndex)\n",
    "\n",
    "# Pre-processing parameters.\n",
    "binning = 1 # Manual selection of detector pixel binning after acqusisition.\n",
    "excludeLastPro = True # Exclude last projection angle which is often the same as the first one.\n",
    "angSubSamp = 1 # Define a sub-sampling factor in angular direction.\n",
    "# (all reference reconstructions are computed with full angular resolution).\n",
    "maxAng = 360 # Maximal angle in degrees - for reconstructions with limited angle (standard: 360).\n",
    "\n",
    "# Correction profiles.\n",
    "# The detector is slightly shifted with respect to the ASTRA geometry specified.\n",
    "# Furthermore, the detector has been changed shortly before 20220531 (between slices 2830 and 2831).\n",
    "# The full correction profiles can be found below.\n",
    "corr_profiles = dict()\n",
    "corr_profiles['20220407_RvL'] = {'det_tan': 24.19, 'src_ort': -5.67, 'axs_tan': -0.5244, 'det_roll': -0.015}\n",
    "corr_profiles['20220531_RvL'] = {'det_tan': 24.4203, 'src_ort': -6.2281, 'axs_tan': -0.5010, 'det_roll': -0.262}\n",
    "\n",
    "# This array contains the simplified horizontal correction shift for both geometries.\n",
    "corr = np.array([2.75, 1.00]) # Found to be the optimal shifts for before and after detector exchange.\n",
    "\n",
    "# File names in dataset structure.\n",
    "sino_name = 'sinogram.tif'\n",
    "dark_name = 'dark.tif'\n",
    "flat_name = ('flat1.tif', 'flat2.tif')\n",
    "slcs_name =\"slice{:05}\"\n",
    "\n",
    "# Reference information.\n",
    "settings = ReadingSettings_2DeteCT.SettingsFile_2DeteCT('./Mode3_settings.csv') # Read in settings file (the mode does not play a role for the recons)\n",
    "sino_dims = (settings.get_parameter('ProjectionsNumber'),settings.get_parameter('ProjectionLength')) # Dimensions of the full sinograms.\n",
    "detPix = settings.get_parameter('DetPixSize') # Physical size of one detector pixel in mm.\n",
    "# Early OOD scans: 5521 - 5870 \n",
    "# Late OOD scans: 5871 - 6370\n",
    "\n",
    "# Reconstruction parameters.\n",
    "recMeth = 'AGD' # Specify which reconstruction algorithm you want to use.\n",
    "recMeths = ['AGD'] # ['FBP', 'LS', 'NNLS', 'SIRT', 'SART', 'CGLS', 'AGD'] # List of reconstruction algorithms to iterate over.\n",
    "recSz = (4096,4096) # Used reconsttuction area to create as little model-inherent artifacts within the FOV.\n",
    "outSz = (2048,2048) # Output size before downscaling corresponding to the FOV.\n",
    "maxIter = 100 # Specify the maximal iteration number.\n",
    "\n",
    "# Visualization of results.\n",
    "visuals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc490d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions.\n",
    "\n",
    "def norm(u):\n",
    "    # L2 norm of u interpreted as a vector.\n",
    "    return np.sqrt(np.sum(u**2))\n",
    "\n",
    "def power_iteration(A, num_simulations):\n",
    "        # Ideally choose a random vector\n",
    "        # To decrease the chance that our vector\n",
    "        # Is orthogonal to the eigenvector.\n",
    "        b_k = np.random.rand(A.shape[1])\n",
    "        b_k1_norm = 1\n",
    "\n",
    "        print('running power iteration to determine step size', flush=True)\n",
    "        for i in range(num_simulations):\n",
    "\n",
    "            # Calculate the matrix-by-vector product Ab.\n",
    "            b_k1 = A.T*A*b_k\n",
    "\n",
    "            # Calculate the norm.\n",
    "            b_k1_norm = np.linalg.norm(b_k1)\n",
    "\n",
    "            # Renormalize the vector.\n",
    "            b_k = b_k1 / b_k1_norm\n",
    "        print('found step size to be:', 1./b_k1_norm , flush=True)\n",
    "        return b_k1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc838818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting reconstruction job...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f222435fe4544203b51c4301422f6e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loop over all methods:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f939ee2265f846268c8662cf220e2eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loop over all desired slices in the dataset:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde1b59a570849868461bf9c53a9dc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loop over all desired acquisition modes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values have been clipped from [ 0.06209030751874151 , 1.0728267484959892 ] to [1e-6,None]\n",
      "Excluded last projection.\n",
      "Data shape: (3600, 1912)\n",
      "Length angles: 3600\n",
      "Loading and pre-processing done\n",
      "Computing reconstruction for slice 10 ...\n",
      "Physical width of FOV (in mm): 116.52814274682939\n",
      "True voxel size (in mm) for 2048 voxels to be used: 0.05689850720060029\n",
      "Self-calculated scale factor: 17.575153535652863\n",
      "running power iteration to determine step size\n",
      "plugin initialized.\n",
      "running 100 iterations of Accelerated Gradient plugin.\n",
      "iteration 0 / 100\n",
      "iteration 10 / 100\n",
      "iteration 20 / 100\n",
      "iteration 30 / 100\n",
      "iteration 40 / 100\n",
      "iteration 50 / 100\n",
      "iteration 60 / 100\n",
      "iteration 70 / 100\n",
      "iteration 80 / 100\n",
      "iteration 90 / 100\n",
      "Shape of cut out reconstruction area: (2048, 2048)\n",
      "272.863 sec elapsed for reconstructing 1 slices.\n"
     ]
    }
   ],
   "source": [
    "# Keep track of the processing time per reconstruction job.\n",
    "t = time.time()\n",
    "print('Starting reconstruction job...', flush=True)\n",
    "\n",
    "# Helper variables.\n",
    "residua = np.zeros((len(slice_id),len(modes),1))\n",
    "slc_counter = 0\n",
    "\n",
    "# Iterate over all methods, all slices, and all modes.\n",
    "for i_meth in tqdm_notebook(range(len(recMeths)), desc = 'Loop over all methods'):\n",
    "    recMeth = recMeths[i_meth]\n",
    "    \n",
    "    for i_slc in tqdm_notebook(slice_id, desc = 'Loop over all desired slices in the dataset'):\n",
    "\n",
    "        for i_mode in tqdm_notebook(modes, desc = 'Loop over all desired acquisition modes'):\n",
    "\n",
    "            # Load and pre-process data.\n",
    "\n",
    "            # Get the current path for respective slice and mode within the dataset structure.\n",
    "            current_path = base_data_dir_str + slcs_name.format(i_slc) + '/mode{}/'.format(i_mode)\n",
    "\n",
    "            # load flat-field and dark-fields.\n",
    "            # There are two flat-field images (taken before and after the acquisition of ten slices),\n",
    "            # we simply average them.\n",
    "            dark = imageio.imread(glob.glob(current_path + dark_name)[0]) \n",
    "            flat1 = imageio.imread(glob.glob(current_path + flat_name[0])[0])\n",
    "            flat2 = imageio.imread(glob.glob(current_path + flat_name[1])[0])\n",
    "            flat = np.mean(np.array([ flat1, flat2 ]), axis=0 )\n",
    "            \n",
    "            # Read in the sinogram.\n",
    "            sinogram = imageio.imread(glob.glob(current_path + sino_name)[0])\n",
    "            sinogram =  np.ascontiguousarray(sinogram)\n",
    "\n",
    "            # Subtract the dark field, devide by the flat field,\n",
    "            # and take the negative log to linearize the data according to the Beer-Lambert law.\n",
    "            data = sinogram - dark\n",
    "            data = data/(flat-dark)\n",
    "            \n",
    "            # Exclude last projection if desired.\n",
    "            if excludeLastPro:\n",
    "                data = data[0:-1,:]\n",
    "\n",
    "            # Create detector shift via linear grid interpolation.\n",
    "            if i_slc in range(1,2830+1) or i_slc in range(5521,5870+1):\n",
    "                detShift = corr[0] * detPix\n",
    "            else:\n",
    "                detShift = corr[1] * detPix\n",
    "            \n",
    "            detGrid = np.arange(0,1912) * detPix\n",
    "            detGridShifted = detGrid + detShift\n",
    "            detShiftCorr = interp1d(detGrid, data, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "            data = detShiftCorr(detGridShifted)\n",
    "\n",
    "            # Clip the data on the lower end to 1e-6 to avoid division by zero in next step.\n",
    "            data = data.clip(1e-6, None)\n",
    "            print(\"Values have been clipped from [\", np.min(data), \",\", np.max(data),\"] to [1e-6,None]\")\n",
    "\n",
    "            # Take negative log.\n",
    "            data = np.log(data)\n",
    "            data = np.negative(data)\n",
    "            data = np.ascontiguousarray(data)\n",
    "\n",
    "            # Create array that stores the used projection angles.\n",
    "            angles = np.linspace(0,2*np.pi, settings.get_parameter('ProjectionsNumber'))\n",
    "            \n",
    "            # Apply exclusion of last projection if desired.\n",
    "            if excludeLastPro:\n",
    "                angles = angles[0:-1]\n",
    "                print('Excluded last projection.')\n",
    "            \n",
    "            # Apply angular subsampling.\n",
    "            data = data[0::angSubSamp,:]\n",
    "            angles = angles[0::angSubSamp]\n",
    "            angInd = np.where(angles<=(maxAng/180*np.pi))\n",
    "            angles = angles[angInd]\n",
    "            data = data[:(angInd[-1][-1]+1),:]\n",
    "\n",
    "            print('Data shape:', data.shape)\n",
    "            print('Length angles:', len(angles))\n",
    "            \n",
    "            print('Loading and pre-processing done', flush=True)\n",
    "\n",
    "            \n",
    "            print('Computing reconstruction for slice', i_slc, '...', flush=True)\n",
    "\n",
    "            # Create ASTRA objects for reconstruction.\n",
    "            detSubSamp = 1\n",
    "            binning = 1\n",
    "            detPixSz = detSubSamp * binning * detPix\n",
    "            SOD = settings.get_parameter('SOD') # Source-Object-Distance for the scanning geometry of the 2DeteCT dataset.\n",
    "            SDD = settings.get_parameter('SDD') # Source-Detector-Distance for the scanning geometry of the 2DeteCT dataset.\n",
    "\n",
    "            # Scale factor calculation.\n",
    "            # ASTRA assumes that the voxel size is 1mm.\n",
    "            # For this to be true we need to calculate a scale factor for the geometry.\n",
    "            # This can be done by first calculating the 'true voxel size' via the intersect theorem\n",
    "            # and then scaling the geometry accordingly.\n",
    "\n",
    "            # Physical width of the detector.\n",
    "            nPix = settings.get_parameter('ProjectionLength')\n",
    "            det_width = detPixSz * nPix\n",
    "\n",
    "            # Physical width of the field of view in the measurement plane via intersect theorem.\n",
    "            FOV_width = det_width * SOD/SDD\n",
    "            print('Physical width of FOV (in mm):', FOV_width)\n",
    "\n",
    "            # True voxel size with a given number of voxels to be used.\n",
    "            nVox = 2048\n",
    "            voxSz = FOV_width / nVox\n",
    "            print('True voxel size (in mm) for', nVox, 'voxels to be used:', voxSz)\n",
    "\n",
    "            # Scaling the geometry accordingly.\n",
    "            scaleFactor = 1./voxSz\n",
    "            print('Self-calculated scale factor:', scaleFactor)\n",
    "            SDD = SDD * scaleFactor\n",
    "            SOD = SOD * scaleFactor\n",
    "            detPixSz = detPixSz * scaleFactor\n",
    "\n",
    "            # Create ASTRA objects.\n",
    "            projGeo = astra.create_proj_geom('fanflat', detPixSz, 1912, angles, SOD, SDD - SOD)\n",
    "            volGeo = astra.create_vol_geom(recSz[0], recSz[1])\n",
    "            recID = astra.data2d.create('-vol', volGeo)\n",
    "            sinoID = astra.data2d.create('-sino', projGeo, data)\n",
    "            projID   = astra.create_projector('cuda', projGeo, volGeo)\n",
    "            A = astra.OpTomo(projID)\n",
    "\n",
    "            if recMeth == 'FBP':\n",
    "                # Create ASTRA configuration.\n",
    "                if use_GPU:\n",
    "                    alg_name = recMeth + '_CUDA'\n",
    "                    cfg = astra.astra_dict(alg_name)\n",
    "                else:\n",
    "                    cfg = astra.astra_dict(recMeth)\n",
    "                    proj_id = astra.create_projector('line_fanflat', projGeo, volGeo)\n",
    "                    cfg['ProjectorId'] = proj_id\n",
    "\n",
    "                cfg['ReconstructionDataId'] = recID\n",
    "                cfg['ProjectionDataId'] = sinoID\n",
    "                cfg['option'] = {'FilterType': 'Ram-Lak', 'MinConstraint': 0.}\n",
    "\n",
    "                # Create and run algorithm.\n",
    "                algID = astra.algorithm.create(cfg)\n",
    "                iterations = maxIter\n",
    "                astra.algorithm.run(algID, iterations)\n",
    "\n",
    "                # Receive reconstruction.\n",
    "                rec = astra.data2d.get(recID)\n",
    "                rec = np.maximum(rec,0)\n",
    "                \n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "\n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                    +'_FBP'+'_iter{}'.format(iterations)+'.tif'), (rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "\n",
    "            elif recMeth == 'LS':\n",
    "                # Use lsqr method from scipy.sparse.linalg to calculate the reconstruction.\n",
    "                rec, istop, itn, residua[slc_counter, i_mode-1, 0]  = lsqr(A,data.flatten(), iter_lim=maxIter)[:4]\n",
    "                print('Iteration stopped because of', istop, 'after', itn, 'iterations with residual',residua[0,i_mode-1,0])\n",
    "                \n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec.reshape(recSz)[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "                \n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)+'_LS'+\n",
    "                                    '_iter{}'.format(itn)+\".tif\"),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "\n",
    "            elif recMeth == 'NNLS':\n",
    "                \n",
    "                # Calculate Lipschitz constant via power iteration.\n",
    "                lipschitz = power_iteration(A,10)\n",
    "                tau = 1e-6 # Specify step-size yourself or use 1./lipschitz.\n",
    "                tau = 1./lipschitz\n",
    "\n",
    "                u = np.zeros(A.vshape) # The unknown reconstructed image.\n",
    "                normF       = norm(data)\n",
    "\n",
    "                # Compute D(f, Au) and grad D(f, Au) at u = 0 (--> Au = 0).\n",
    "                residuum     = - data \n",
    "                relResNorm   = 1.0\n",
    "                Du           = 0.5 * np.sum(residuum**2)\n",
    "                gradDu       = A.BP(residuum)\n",
    "\n",
    "                # Computing the variational energy J(u) and its gradient.\n",
    "                Ju, gradJu   = Du, gradDu            \n",
    "\n",
    "                # Projected gradient descent iteration.\n",
    "                for iter in tqdm_notebook(range(maxIter+1)):\n",
    "\n",
    "                    # Update u by a gradient step followed by a projection.\n",
    "                    uNew = u - tau * gradJu\n",
    "\n",
    "                    # Activate non-negativity constraint.\n",
    "                    uNew[uNew < 0] = 0\n",
    "\n",
    "                    # Compute D(f, Au) and grad D(f, Au) at uNew.\n",
    "                    residuumNew     = A.FP(uNew) - data\n",
    "                    relResNormNew   = norm(residuumNew) / normF # To make the residuum comparable to fitted term f.\n",
    "                    DuNew           = 0.5 * np.sum(residuumNew**2)\n",
    "                    gradDuNew       = A.BP(residuumNew)\n",
    "\n",
    "                    # Compute variational energy J(u) and its gradient grad J(u) at uNew.\n",
    "                    JuNew, gradJuNew = DuNew, gradDuNew\n",
    "\n",
    "                    if JuNew > Ju:\n",
    "\n",
    "                        # Discard update step and decrease step size.  \n",
    "                        tau      = 0.9 * tau\n",
    "                        changeU, changeJu = 0.0, 0.0\n",
    "\n",
    "                    else:\n",
    "                        # Accept new c.\n",
    "                        # For displaying purposes compute the rel. change of u and J(u).\n",
    "                        changeU       = norm(uNew - u)   / norm(uNew)\n",
    "                        changeJu      = (Ju - JuNew) / Ju\n",
    "\n",
    "                        # Update the variables with new values.\n",
    "                        u, Ju, gradJu = uNew, JuNew, gradJuNew\n",
    "\n",
    "                    # Display some output now and then.\n",
    "                    if not(iter % 100):\n",
    "                        print(\"it: {:-6}; Ju: {:1.6e} (rel change: {:1.3e}); rel change u: {:1.3e}; tau: {:1.3e}\".format(\n",
    "                            iter, Ju, changeJu, changeU, tau))\n",
    "                    \n",
    "                    # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                    if iter == maxIter:\n",
    "                        rec_cut = u[1023:3071,1023:3071]\n",
    "                        print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "                        \n",
    "                        # Save reconstruction.\n",
    "                        imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                            +'_NNLS_iter'+str(iter)+'.tif'),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "            elif recMeth == 'SIRT':\n",
    "                \n",
    "                # Create configuration.\n",
    "                if use_GPU:\n",
    "                    alg_name = recMeth + '_CUDA'\n",
    "                    cfg = astra.astra_dict(alg_name)\n",
    "                else:\n",
    "                    cfg = astra.astra_dict(recMeth)\n",
    "                    proj_id = astra.create_projector('fanflat', projGeo, volGeo)\n",
    "                    cfg['ProjectorId'] = proj_id\n",
    "\n",
    "                cfg['ReconstructionDataId'] = recID\n",
    "                cfg['ProjectionDataId'] = sinoID\n",
    "                cfg['option'] = {'MinConstraint': 0}\n",
    "\n",
    "                # Create and run algorithm.\n",
    "                algID = astra.algorithm.create(cfg)\n",
    "                iterations = maxIter\n",
    "                astra.algorithm.run(algID, iterations)\n",
    "\n",
    "                # Receive reconstruction.\n",
    "                rec = astra.data2d.get(recID)\n",
    "                rec = np.maximum(rec,0) \n",
    "\n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "\n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                    +'_SIRT_iter'+str(iterations)+'.tif'),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "            elif recMeth == 'SART':\n",
    "                \n",
    "                # Create configuration.\n",
    "                if use_GPU:\n",
    "                    alg_name = recMeth + '_CUDA'\n",
    "                    cfg = astra.astra_dict(alg_name)\n",
    "                else:\n",
    "                    cfg = astra.astra_dict(recMeth)\n",
    "                    proj_id = astra.create_projector('fanflat', projGeo, volGeo)\n",
    "                    cfg['ProjectorId'] = proj_id\n",
    "\n",
    "                cfg['ReconstructionDataId'] = recID\n",
    "                cfg['ProjectionDataId'] = sinoID\n",
    "                cfg['option'] = {'MinConstraint': 0}\n",
    "\n",
    "                # Create and run algorithm.\n",
    "                algID = astra.algorithm.create(cfg)\n",
    "                iterations = maxIter\n",
    "                astra.algorithm.run(algID, iterations)\n",
    "\n",
    "                # Receive reconstruction.\n",
    "                rec = astra.data2d.get(recID)\n",
    "                rec = np.maximum(rec,0) \n",
    "                \n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "\n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                    +'_SART_iter'+str(iterations)+'.tif'),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "            elif recMeth == 'CGLS':\n",
    "                \n",
    "                # Create configuration.\n",
    "                if use_GPU:\n",
    "                    alg_name = recMeth + '_CUDA'\n",
    "                    cfg = astra.astra_dict(alg_name)\n",
    "                else:\n",
    "                    cfg = astra.astra_dict(recMeth)\n",
    "                    proj_id = astra.create_projector('fanflat', projGeo, volGeo)\n",
    "                    cfg['ProjectorId'] = proj_id\n",
    "\n",
    "                cfg['ReconstructionDataId'] = recID\n",
    "                cfg['ProjectionDataId'] = sinoID\n",
    "\n",
    "                # Create and run algorithm.\n",
    "                algID = astra.algorithm.create(cfg)\n",
    "                iterations = maxIter\n",
    "                astra.algorithm.run(algID, iterations)\n",
    "\n",
    "                # Receive reconstruction.\n",
    "                rec = astra.data2d.get(recID)\n",
    "                rec = np.maximum(rec,0) \n",
    "\n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "                \n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                        +'_CGLS_iter'+str(iterations)+'.tif'),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "\n",
    "            \n",
    "            elif recMeth == 'AGD':\n",
    "                \n",
    "                # Create an ASTRA configuration using a registered plugin.\n",
    "                # This configuration dictionary setups an algorithm,\n",
    "                # a projection and a volume geometry and returns\n",
    "                # an ASTRA algorithm, which can be run on its own.\n",
    "                \n",
    "                astra.plugin.register(NesterovGradient.AcceleratedGradientPlugin)\n",
    "                proj_id = astra.create_projector('cuda', projGeo, volGeo)\n",
    "                cfg_agd = astra.astra_dict('AGD-PLUGIN')\n",
    "                cfg_agd['ReconstructionDataId'] = recID\n",
    "                cfg_agd['ProjectionDataId'] = sinoID\n",
    "                cfg_agd['ProjectorId'] = proj_id\n",
    "                cfg_agd['option'] = {}\n",
    "                cfg_agd['option']['MinConstraint'] = 0\n",
    "                \n",
    "                # Create and run algorithm.\n",
    "                algID = astra.algorithm.create(cfg_agd)\n",
    "                iterations = maxIter\n",
    "                astra.algorithm.run(algID, iterations)\n",
    "\n",
    "                # Receive reconstruction.\n",
    "                rec = astra.data2d.get(recID)\n",
    "                rec = np.maximum(rec,0)\n",
    "                \n",
    "                # Cut the reconstruction to the desired area of (2048,2048).\n",
    "                rec_cut = rec[1023:3071,1023:3071]\n",
    "                print('Shape of cut out reconstruction area:', rec_cut.shape)\n",
    "                \n",
    "                # Save reconstruction.\n",
    "                imageio.imwrite(str(save_dir_str+\"recon_\"+ slcs_name.format(i_slc) + '_mode{}'.format(i_mode)\n",
    "                                                +'_AGD_iter'+str(iterations)+'.tif'),(rec_cut.astype(np.float32)).reshape(outSz))\n",
    "            \n",
    "            if visuals:                \n",
    "                plt.imshow(rec_cut, cmap='gray')                \n",
    "\n",
    "            # Clean up.\n",
    "            astra.algorithm.delete(algID)\n",
    "            astra.data2d.delete(recID)\n",
    "            astra.data2d.delete(sinoID)\n",
    "            \n",
    "            if not use_GPU:\n",
    "                astra.projector.delete(proj_id)\n",
    "        \n",
    "        # Update counter for LS to store residua.\n",
    "        if recMeth == 'LS':\n",
    "            slc_counter +=1\n",
    "\n",
    "print(np.round_(time.time() - t, 3), 'sec elapsed for reconstructing', len(slice_id), 'slices.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9b4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomosipo_recons",
   "language": "python",
   "name": "tomosipo_recons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
